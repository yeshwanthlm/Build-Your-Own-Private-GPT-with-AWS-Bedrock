# Build Your Own Private GPT with AWS Bedrock

A serverless AI chat application that allows users to interact with an AWS Bedrock Knowledge Base. This example demonstrates how to build a private GPT-style chatbot for the AWS Certified Solutions Architect - Professional (SAP-C02) exam preparation, but can be adapted for any knowledge base content.

[![AWS](https://img.shields.io/badge/AWS-Bedrock-FF9900?style=for-the-badge&logo=amazon-aws&logoColor=white)](https://aws.amazon.com/bedrock/)
[![Terraform](https://img.shields.io/badge/Terraform-7B42BC?style=for-the-badge&logo=terraform&logoColor=white)](https://www.terraform.io/)
[![Python](https://img.shields.io/badge/Python-3.11-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)](LICENSE)

> ğŸš€ Build your own AI-powered chatbot with AWS Bedrock, Lambda, and CloudFront in minutes!

## ğŸ—ï¸ Architecture

```
User Browser
    â†“ (HTTPS)
CloudFront CDN
    â†“
S3 Static Website
    â†“ (API Calls)
API Gateway
    â†“
Lambda Function
    â†“
AWS Bedrock Knowledge Base
    â†“
Claude 3 Sonnet Model
```

**Components:**
- **Frontend**: HTML/CSS/JavaScript chat interface hosted on S3 + CloudFront
- **API Gateway**: HTTP API with CORS enabled
- **Lambda Function**: Python 3.11 function to query Bedrock Knowledge Base
- **Bedrock Knowledge Base**: Your custom knowledge base with uploaded documents
- **Infrastructure**: Fully managed with Terraform (IaC)

## ğŸ“‹ Prerequisites

Before you begin, ensure you have:

- **AWS Account** with appropriate permissions
- **AWS CLI** configured with credentials
- **Terraform** >= 1.0 installed
- **Python** 3.10+ installed
- **AWS Bedrock Knowledge Base** created with your documents
- **IAM Permissions** for:
  - Lambda
  - API Gateway
  - S3
  - CloudFront
  - Bedrock (Retrieve and RetrieveAndGenerate)
  - IAM role creation

### Setting Up Your Knowledge Base

1. Go to AWS Bedrock Console
2. Create a Knowledge Base
3. Upload your documents (PDFs, text files, etc.)
4. Note your Knowledge Base ID
5. Update `terraform/variables.tf` with your Knowledge Base ID

## Project Structure

```
.
â”œâ”€â”€ terraform/
â”‚   â”œâ”€â”€ main.tf           # Main infrastructure configuration
â”‚   â”œâ”€â”€ variables.tf      # Terraform variables
â”‚   â””â”€â”€ outputs.tf        # Output values
â”œâ”€â”€ lambda/
â”‚   â”œâ”€â”€ index.py          # Lambda function code
â”‚   â””â”€â”€ requirements.txt  # Python dependencies
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html        # Chat interface
â”‚   â”œâ”€â”€ styles.css        # Styling
â”‚   â””â”€â”€ app.js           # Frontend logic
â”œâ”€â”€ deploy.sh            # Deployment script
â””â”€â”€ README.md
```

## Deployment

### Option 1: Automated Deployment

```bash
chmod +x deploy.sh
./deploy.sh
```

### Option 2: Manual Deployment

1. **Package Lambda function:**
```bash
cd lambda
pip install -r requirements.txt -t .
zip -r ../terraform/lambda_function.zip .
cd ..
```

2. **Deploy infrastructure:**
```bash
cd terraform
terraform init
terraform plan
terraform apply
```

3. **Get API endpoint:**
```bash
terraform output api_url
```

4. **Update frontend:**
Edit `frontend/app.js` and replace `YOUR_API_ENDPOINT_HERE` with the API URL from step 3.

## Configuration

### Terraform Variables

You can customize the deployment by modifying `terraform/variables.tf` or creating a `terraform.tfvars` file:

```hcl
aws_region        = "us-east-1"
project_name      = "my-private-gpt"
knowledge_base_id = "YOUR_KNOWLEDGE_BASE_ID"  # Replace with your KB ID
bedrock_model_id  = "arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0"
```

**Important**: Update the `knowledge_base_id` with your actual Bedrock Knowledge Base ID!

### Lambda Environment Variables

The Lambda function uses the following environment variables:
- `KNOWLEDGE_BASE_ID`: Your Bedrock Knowledge Base ID
- `BEDROCK_MODEL_ARN`: The Bedrock model to use for generation (default: Claude 3 Sonnet)

### Customizing System Instructions

The Lambda function includes system instructions that guide the AI's behavior. You can customize these by editing the `system_instruction` variable in `lambda/index.py` to match your use case:

```python
system_instruction = """You are an expert assistant for [YOUR DOMAIN].
Your role is to:
1. Provide accurate information based on the knowledge base
2. [Add your specific requirements]
3. [Customize behavior as needed]
"""
```

## Usage

1. Open `frontend/index.html` in your web browser
2. Type your question about the SAP-C02 exam
3. Click "Send" or press Enter
4. View the AI-generated response with citations

### Example Questions (SAP-C02 Use Case)

- "What are the key domains covered in the SAP-C02 exam?"
- "What is the passing score for the AWS Solutions Architect Professional exam?"
- "What topics are covered in the Design for Organizational Complexity domain?"

**Note**: Customize these examples based on your knowledge base content!

## API Endpoint

### POST /query

**Request:**
```json
{
  "query": "What are the exam domains?"
}
```

**Response:**
```json
{
  "answer": "The exam covers four domains...",
  "citations": [
    {
      "content": "Reference text...",
      "location": {}
    }
  ]
}
```

## Cleanup

To destroy all created resources:

```bash
cd terraform
terraform destroy
```

## ğŸ› Troubleshooting

### Lambda Timeout
If queries take too long, increase the timeout in `terraform/main.tf`:
```hcl
timeout = 60  # Increase from 30 to 60 seconds
```

### CORS Issues
The API Gateway is configured to allow all origins (`*`). For production, update the CORS configuration in `terraform/main.tf` to restrict to your domain:
```hcl
allow_origins = ["https://yourdomain.com"]
```

### Bedrock Access
Ensure your AWS account has:
- Access to AWS Bedrock service
- Permissions for your Knowledge Base ID
- Model access enabled for Claude 3 Sonnet

### Frontend Not Loading
If opening `index.html` directly causes CORS errors, use the local server:
```bash
cd frontend
python3 -m http.server 8000
```
Then open http://localhost:8000

Or deploy to S3 + CloudFront (included in Terraform)

## ğŸ”’ Security Considerations

For production deployments, consider:

- âœ… **CORS**: Restrict to specific domains instead of `*`
- âœ… **Authentication**: Implement AWS Cognito or API keys
- âœ… **WAF**: Use AWS WAF to protect API Gateway
- âœ… **Logging**: Enable CloudWatch logs for monitoring
- âœ… **Encryption**: Enable S3 bucket encryption
- âœ… **IAM**: Follow principle of least privilege
- âœ… **Rate Limiting**: Implement API throttling
- âœ… **Secrets**: Use AWS Secrets Manager for sensitive data

## ğŸ’° Cost Estimation

**Estimated Monthly Cost: $1-5** (with moderate usage)

| Service | Cost | Free Tier |
|---------|------|-----------|
| S3 Storage | ~$0.02 | 5GB |
| CloudFront | ~$0.10 | 1TB data transfer |
| API Gateway | ~$1.00 | 1M requests |
| Lambda | ~$0.20 | 1M requests, 400K GB-seconds |
| Bedrock | Variable | ~$0.003 per 1K tokens |
| CloudWatch Logs | ~$0.50 | 5GB ingestion |

**Total**: ~$1-5/month depending on usage

ğŸ’¡ **Tip**: Most costs come from Bedrock token usage. Monitor your usage in AWS Cost Explorer.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ‘¨â€ğŸ’» Author

**Yeshwanth Lakkireddy**
- GitHub: [@yeshwanthlm](https://github.com/yeshwanthlm)
- LinkedIn: [Yeshwanth Lakkireddy](https://www.linkedin.com/in/yeshwanthlm/)

## â­ Show Your Support

Give a â­ï¸ if this project helped you!

## ğŸ™ Acknowledgments

- AWS Bedrock Team for the amazing AI services
- Anthropic for Claude 3 Sonnet
- HashiCorp for Terraform
- The open-source community
